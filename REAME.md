# ğŸ¥ YOLO Live Video Inference Web App (FastAPI + Redis)

## ğŸš€ Overview

This project is a **real-time video inference platform** built with **FastAPI**, **Redis**, and **YOLOv8/YOLO11** models.  
Users can upload a video, select their preferred YOLO model, and watch **frame-by-frame live inference** directly on the web interface.  
All inference frames are temporarily stored in **Redis cache** for up to **30 minutes** or until the user downloads the final video.

---

## âœ¨ Key Features

- ğŸ§  **Model Selection:** Choose between `yolov8n` and `yolo11n` models (local `.pt` weights supported).  
- âš¡ **Live Inference:** Displays frame-by-frame inference progress in real time.  
- ğŸ•“ **Progress Bar:** Visual progress tracking for ongoing inference jobs.  
- ğŸ’¾ **Redis Cache Storage:** Stores inference frames and metadata temporarily for 30 minutes.  
- ğŸ“Š **Performance Metrics:** Shows average FPS, total inference time, and model details after completion.  
- ğŸ“¥ **Downloadable Video:** Once inference completes, users can download the fully processed video.  
- ğŸ”’ **Isolated Jobs:** Each video inference runs independently using a unique job ID.

---

## ğŸ§© Tech Stack

| Component | Description |
|------------|--------------|
| **Backend** | [FastAPI](https://fastapi.tiangolo.com/) |
| **Frontend** | HTML, CSS, Vanilla JavaScript |
| **Model Inference** | [Ultralytics YOLO](https://docs.ultralytics.com/) (v8 & v11 supported) |
| **Cache / Job Queue** | [Redis](https://redis.io/) |
| **Video Encoding** | [FFmpeg](https://ffmpeg.org/) |

---

## ğŸ“‚ Project Structure

liveInferenceWithRedis/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI app entry point
â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â”œâ”€â”€ inference_router.py
â”‚ â”‚ â””â”€â”€ upload_router.py
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â”œâ”€â”€ runner.py # YOLO inference handler
â”‚ â”‚ â”œâ”€â”€ redis_client.py # Redis cache interface
â”‚ â”‚ â””â”€â”€ ffmpeg_utils.py # Video encoding utilities
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â””â”€â”€ weights/
â”‚ â”‚ â”œâ”€â”€ yolov8n.pt
â”‚ â”‚ â””â”€â”€ yolo11n.pt
â”‚ â”œâ”€â”€ static/
â”‚ â”‚ â”œâ”€â”€ styles.css
â”‚ â”‚ â””â”€â”€ app.js
â”‚ â””â”€â”€ templates/
â”‚ â””â”€â”€ index.html
â”œâ”€â”€ tmp/ # Temporary job directories for frames/videos
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Setup Instructions

### 1ï¸ Clone the Repository

git clone https://github.com/yourusername/liveInferenceWithRedis.git
cd liveInferenceWithRedis

### 2 Virtual Env
python -m venv venv
venv\Scripts\activate   # On Windows
# or
source venv/bin/activate  # On Linux/Mac

### 3 Install req
pip install -r requirements.txt

### 4 Run Redis Server
redis-server

### 5 Run main.py
uvicorn app.main:app --reload



### You can inspect using Redis CLI:

redis-cli
KEYS *


ğŸ‘¨â€ğŸ’» Author

Shaikh Azan
ğŸ’¼ AI & Software Engineer
ğŸ“§ [azanasim1@example.com]
ğŸŒ [https://github.com/ShaikhAzanAsim]